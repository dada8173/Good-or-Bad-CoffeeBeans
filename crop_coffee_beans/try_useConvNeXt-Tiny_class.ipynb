{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ec7a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é¡åˆ¥å°æ‡‰: {'bad': 0, 'good': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40:  32%|â–ˆâ–ˆâ–ˆâ–      | 9/28 [00:03<00:05,  3.24it/s, acc=53.5, loss=0.795]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.models import convnext_tiny\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# EarlyStopping é¡åˆ¥\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=8, delta=0, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_acc = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        self.best_model_state = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __call__(self, acc, model):\n",
    "        if self.best_acc is None:\n",
    "            self.best_acc = acc\n",
    "            self.best_model_state = model.state_dict()\n",
    "        elif acc < self.best_acc + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"âš ï¸ æ—©åœè¨ˆæ•¸: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            if self.verbose:\n",
    "                print(f\"âœ… é©—è­‰æº–ç¢ºåº¦æå‡: {self.best_acc:.2f} â†’ {acc:.2f}ï¼Œé‡ç½®è¨ˆæ•¸\")\n",
    "            self.best_acc = acc\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0\n",
    "\n",
    "# è£ç½®è¨­å®š\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# åœ–åƒè™•ç†\n",
    "dataset_path = \"corp_augmented_data\"\n",
    "batch_size = 128\n",
    "img_size = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# è³‡æ–™é›†\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"é¡åˆ¥å°æ‡‰: {dataset.class_to_idx}\")\n",
    "\n",
    "# æ¨¡å‹\n",
    "model = convnext_tiny(weights=None)\n",
    "model.classifier[2] = nn.Linear(model.classifier[2].in_features, 2)\n",
    "model = model.to(device)\n",
    "\n",
    "# æå¤±èˆ‡å„ªåŒ–å™¨\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "early_stopper = EarlyStopping(patience=6)\n",
    "# è¨“ç·´è®Šæ•¸\n",
    "num_epochs = 40\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# è¨“ç·´è¿´åœˆ\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for images, labels in progress:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        progress.set_postfix(loss=loss.item(), acc=100 * correct / total)\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    print(f\"ğŸ§  Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "    # é©—è­‰\n",
    "    model.eval()\n",
    "    val_running_loss = 0\n",
    "    val_correct, val_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "            _, preds = outputs.max(1)\n",
    "            val_correct += preds.eq(labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    avg_val_loss = val_running_loss / len(test_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    print(f\"ğŸ“‰ é©—è­‰ Loss: {avg_val_loss:.4f}, æº–ç¢ºç‡: {val_acc:.2f}%\")\n",
    "\n",
    "    # æª¢æŸ¥æ—©åœ\n",
    "    early_stopper(val_acc, model)\n",
    "    if early_stopper.early_stop:\n",
    "        print(\"ğŸ›‘ æ—©åœè§¸ç™¼ï¼Œè¨“ç·´çµ‚æ­¢\")\n",
    "        break\n",
    "\n",
    "# å„²å­˜æœ€ä½³æ¨¡å‹\n",
    "torch.save(early_stopper.best_model_state, \"convnext_tiny_coffeebean_best.pth\")\n",
    "print(\"ğŸ“¦ æ¨¡å‹å·²å„²å­˜\")\n",
    "\n",
    "# æ¸¬è©¦\n",
    "model.load_state_dict(early_stopper.best_model_state)\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"âœ… æ¸¬è©¦æº–ç¢ºç‡: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# ğŸ” ç¹ªè£½ Loss & Accuracy æ›²ç·š\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss æ›²ç·š\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Accuracy æ›²ç·š\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Acc')\n",
    "plt.plot(val_accuracies, label='Val Acc')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"loss_acc_curve.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
